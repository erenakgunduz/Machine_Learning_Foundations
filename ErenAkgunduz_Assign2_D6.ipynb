{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment \\#2, Deliverable 6\n",
    "## Eren Akgunduz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger\n",
    "\n",
    "The logging system **definitely** came in handy when I was testing my code in the Python script. Although it *does* also work within this notebook, I feel that it's unnecessary and creates clutter for the outputs. In the interest of displaying only the necessary plots and info, I changed the logging level here to warnings only (to keep it quiet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "\n",
    "fh = logging.StreamHandler()\n",
    "fmt = logging.Formatter(\n",
    "    \"%(asctime)s %(levelname)s %(lineno)d:%(filename)s(%(process)d) - %(message)s\"\n",
    ")\n",
    "fh.setFormatter(fmt)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- all tuning parameters ---\n",
    "l = np.logspace(-2, 6, 9)  # lambda, from 1e-2 to 1e6, and with nine total samples\n",
    "a = np.linspace(0, 1, 6)  # alpha, from 0 to 1, now with six evenly spaced samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(filename: str) -> tuple:\n",
    "    \"Take in raw data and convert it to a workable format/state\"\n",
    "    if not isinstance(filename, str):\n",
    "        raise TypeError(\"Filename should be a string :)\")\n",
    "\n",
    "    try:\n",
    "        datafile = f\"{os.getcwd()}/{filename}\"\n",
    "        logger.debug(datafile)\n",
    "        if not os.path.exists(datafile):\n",
    "            raise OSError(\"Expected data file, didn't find it :/\")\n",
    "\n",
    "        df = pd.read_csv(datafile, sep=\",\")  # read and pass to dataframe\n",
    "        # debug shows that scikit-learn has mapped male to 1 and female to 0\n",
    "        df[[\"Gender\", \"Student\", \"Married\"]] = OrdinalEncoder().fit_transform(\n",
    "            df[[\"Gender\", \"Student\", \"Married\"]]\n",
    "        )\n",
    "        logger.debug(df[[\"Gender\", \"Student\", \"Married\"]].head(10))\n",
    "\n",
    "        # convert dataframe to numpy array for faster computations\n",
    "        return (df.columns.to_numpy(), np.array(df))\n",
    "    except OSError:\n",
    "        print(\"Couldn't load in the data due to OS error.\")\n",
    "        sys.exit(\"Check if things are right and try again :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data) -> tuple:\n",
    "    \"Establish design matrix and response vector, prepare both for elastic net\"\n",
    "    y = data[:, 9]  # extract only the data from the output column (balance)\n",
    "    y = (lambda c: c - c.mean())(y)  # IIFE to center response vector\n",
    "    logger.debug(y.shape)\n",
    "    logger.debug(y.mean())\n",
    "\n",
    "    dm = np.delete(data, 9, axis=1)  # extract the design matrix\n",
    "    X = StandardScaler().fit_transform(dm)  # standardize (center & scale)\n",
    "\n",
    "    logger.debug(X.shape)\n",
    "    logger.debug([np.mean(X[:, k]) for k in range(X.shape[1])])\n",
    "    logger.debug([np.std(X[:, k]) for k in range(X.shape[1])])\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net(X, y, l, a, cv: bool = False, k: int = 5) -> np.ndarray:\n",
    "    if not isinstance(k, int):\n",
    "        raise TypeError(\"Number of folds should be an integer :)\")\n",
    "\n",
    "    coeffs = np.zeros((6, 9, 9))\n",
    "    cv_errors = np.zeros((9, 6, 5))\n",
    "\n",
    "    def en(l, a):\n",
    "        elastic = ElasticNet(alpha=l, l1_ratio=a)\n",
    "        elastic.fit(X, y)\n",
    "        return elastic.coef_\n",
    "\n",
    "    if not isinstance(l, (int, float)) and not isinstance(a, (int, float)):\n",
    "        for i_a, val_a in enumerate(np.flip(a)):\n",
    "            for i_l, val_l in enumerate(l):\n",
    "                if cv:\n",
    "                    cv_errors[i_l, i_a] = np.abs(\n",
    "                        cross_val_score(\n",
    "                            ElasticNet(alpha=val_l, l1_ratio=val_a),\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=k,\n",
    "                            scoring=\"neg_mean_squared_error\",\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    coeffs[i_a, i_l] = en(val_l, val_a)\n",
    "    else:\n",
    "        coeffs = en(l, a)\n",
    "\n",
    "    if cv:\n",
    "        logger.debug(f\"{cv_errors.shape}\\n{cv_errors}\")\n",
    "        logger.debug(cv_errors.mean(axis=2))\n",
    "        return cv_errors.mean(axis=2)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, data = preprocess_data(\"Credit_N400_p9.csv\")  # unpack the tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable \\#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = standardize(data)\n",
    "B = elastic_net(X, y, l, a)\n",
    "logger.debug(f\"{B.shape}\\n{B}\")\n",
    "for index, alpha in enumerate(B):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.xscale(\"log\")\n",
    "    # transpose so that each row is one of the nine features with the nine columns for TP\n",
    "    # this way, each index (row) has the vector I need to plot points\n",
    "    [plt.plot(l, b, label=f\"{columns[i]}\") for i, b in enumerate(alpha.T)]\n",
    "    plt.xlabel(r\"Tuning parameter ($\\lambda$)\")\n",
    "    plt.ylabel(r\"Regression coefficients ($\\hat{\\beta}$)\")\n",
    "    plt.legend(title=\"Features\", fontsize=\"small\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable \\#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = elastic_net(X, y, l, a, True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xscale(\"log\")\n",
    "[plt.plot(l, cv, label=f\"{round(a[i], 1)}\") for i, cv in enumerate(cv_error.T)]\n",
    "plt.xlabel(r\"Tuning parameter ($\\lambda$)\")\n",
    "plt.ylabel(r\"$CV_{(5)}$ mean squared error\")\n",
    "plt.legend(title=r\"$\\alpha$\", fontsize=\"small\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable \\#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(cv_error.argmin())\n",
    "logger.debug(cv_error.min())\n",
    "logger.debug(\n",
    "    cv_error[\n",
    "        cv_error.argmin() // cv_error.shape[1],  # gets the row\n",
    "        cv_error.argmin() % cv_error.shape[1],  # gets the column\n",
    "    ]\n",
    ")\n",
    "l_optimal = float(l[cv_error.argmin() // cv_error.shape[1]])\n",
    "a_optimal = float(a[cv_error.argmin() % cv_error.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_optimal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable \\#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = elastic_net(X, y, l_optimal, a_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = elastic_net(X, y, l_optimal, a[0])  # lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = elastic_net(X, y, l_optimal, a[5])  # ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
